```
目标：把广东的接到上海



C接口接入


新增站点
	站点下区域

数据插入
	修改xlsx -- 站点名、机房id、机房名不能重复

执行xlsx
	修改对应config数据库
	
启动c接口模拟器
	到10.1.203.38里面
	需要修改socket

修改数据库表
	SELECT * FROM t_cfg_site_mapping
		修改csvrip为c接口所起的服务、port为模拟器里面的port

t_cfg_site_mapping解析
	通过province_name来识别要接入的是哪一个省份的c接口
	lsc_id和lsc_name对应站点的名字
	mapping_name——对应中间库的sitename，即模拟器上显示的
	
	同个province_name下的mapping_name 不能重复
	
	需要写入对用数据
		一个是真是对应省份的站点id    01-01-08-04-11   01-01-23-03-06
		一个是对应中间库中的站点展示
		
		
重启c服务
	在10.1.203.121里面
	
重新触发定时任务
	需要改为c接口对应ip和端口，或者直接到c接口里面，只需要改端口（nacos里面可以看）
		注意就是sc里面的
	站点为上面的
	curl --location  'http://localhost:8272/v1/cinterface/startSyncTimer'
	curl --location 'http://localhost:8272/v1/cinterface/compareAndSyncBySite?operateUser=chw-0919&siteId=01-01-08-04-11&justCompare=false'
	
	
	01-01-28-01-01
		
	curl --location 'http://localhost:8272/v1/cinterface/compareAndSyncBySite?operateUser=chw-0919&siteId=01-01-28-01-01&justCompare=false'

	
	
docker restart 63b44ff0d797



2、



SOCKET_PORT = 8032
HTTP_PORT = 8033
MYSQL_CONN_STR = "mysql+pymysql://root:GPGAErA%ZkhMk59*jaD@10.1.203.120:3306/cinterdb_gd?charset=utf8&autocommit=true"
#MYSQL_CONN_STR = "mysql+pymysql://root:G$SGp!8L3O@10.1.203.38:3306/cinterdb_400_dcim?charset=utf8&autocommit=true"
```



```
接入与接出理解
	接入：
		指的是将别的sc接入到另一个sc里面【即把广东的数据接入到上海的数据  --  是不是与fsu类似】
		是否可以理解成：
			C模拟器，就是模拟器sc的数据产生【可以接多个、就相当于我的sc里面的数据不是直接从fsu来，而是从sc来】
			与B接口，fsu传到sc的概念其实是差不多的？
		是否是统计接入站点下所有设备的值呢
			如果上海里面建立多个机房，那每个机房的数据就都是一样的吗



（1）C接口接入服务到中间库的网络策略放通
（2）C接口接入服务到TCP服务端的网络策略放通

```





# 步骤1

## C模拟器部署

```
这个为可选项【如果已有对应身份模拟器，并且端口与对应省份C接口服务的端口一致，就可以直接使用】


以上海为例【接入广东lsc】
	C模拟器环境选择【目前是在10.1.203.38这个服务上】
		关于项目的的导入【目前是使用cp -r直接复制dcim的；也可以直接通过svn上的lsc_400导入服务器进行部署】
		其次需要修改config.py文件
			需要修改参数
				socket：这个对应C接口的端口【现在这里定义好C接口的端口、同时需要到C接口对应服务看这个端口是否已经存在，存在需换一个 -- 10.1.203.121】
					8272
				http：这个是C模拟器的端口【也需要看目前服务下，是否已经被应用了；即在10.1.203.38这个服务上  -- lsof -i:端口查看】
					8033
				每次修改无需重启、会有热启动机制自动加载
		紧接着运行启动即可
			可以看nohup日志【日志主要看C模拟器启动的请求、C模拟器数据相应--这个不太清除】
```

# 步骤2

## 数据准备到中间库

```
这里主要是把站点、机房、设备、测点的结构写道中间库，用于后面站点映射时候，映射过去【即把整个结构迁过去】


C模拟器项目中的lsc400_data.xlsx文件[只需修改下面两个sheet，其余不用]
	m_site
		siteID：站点id				任意命名，但是不能与中间库中的m_site中重复,如果同时创建多个也不能重复
		siteName：站点名		    用于后续站点映射配置的时候填写
		sitetype:站点类型
	m_room
		roomid：机房id				任意命名，每个机房对应一个room_id
		siteid：站点id
		roomtype：机房类型
		roomname：机房名字

执行C400基础数据准备.py
	需要先配置config.py的中间库信息【目前中间库是用的10.1.203.120，即上海对应的数据中的中间库】
	MYSQL_CONN_STR = "mysql+pymysql://root:GPGAErA%ZkhMk59*jaD@10.1.203.120:3306/cinterdb_gd?charset=utf8&autocommit=true"


注意点：
	可以一次性创建多个site【m_site】，如果在创建的时候出现错误，那么需要先到中间库把对应的siteid删除
	一个站点可以创建多个机房【m_room】
```

# 步骤3

## 配置表数据插入

| 数据库属性  | 解释                                                         |
| ----------- | ------------------------------------------------------------ |
| lsc_id      | C接口标识【需要与目前动环库里t_cfg_cserverinfo的lsc前两位不一致、后续nacos配置列表中c接口配置的lsc就取这个】 |
| dbsvrip     | 中间库ip                                                     |
| dbsvrport   | 中间库端口号，通常为3306                                     |
| dbname      | 中间库库名                                                   |
| dblogname   | 中间库用户名                                                 |
| dblogpwd    | 中间库密码                                                   |
| csvrip      | TCP服务端ip                                                  |
| csvrport    | TCP服务端端口号                                              |
| clogusrname | TCP服务端用户名                                              |
| clogusrname | TCP服务端密码                                                |

```
这里主要是对动环库中t_cfg_cserverinfo表的C模拟器和数据库的配置


在对应环境的动环库插入
	以上海为例
		那就是在10.1.203.120数据库的sc-spider数据库里面的t_cfg_cserverinfo表
			参数讲解
				dbsvrip：就是10.1.203.120的中间库【目前用的现有的cinterdb_gd】
				dbsvrport:3306【基本都是这个】
				dbname：cinterdb_gd【可以自己重新生成，这个无所谓】
				dblogname：root【默认都是这个】
				dblogpwd：数据库密码【可以在nacos里面找到对应环境数据库密码】
				
				csvrip：C模拟器所部署的服务器【目前上海的c模拟器部署在10.1.203.38上】
				csvrport：C模拟器的config中的socket端口【这里的端口对应配置文件中的端口，这里配啥，到时候yml文件就需要改为什么才能对应，目前8272】
				clogusrname：hyzomc【好像都是这个】
				clogusrname：hyzomc@2023【好像都是这个】
				
		
前人提供
INSERT INTO t_cfg_cserverinfo
(lsc_id, lsc_name, csvrip, csvrport, clogusrname, clogusrpwd, dbtype, dbsvrip, dbsvrport, dbname, dblogname, dblogpwd, access_device_id, protocol_id)
VALUES(571, '云南-接入', '10.173.101.36', 31020, 'hyzomc', 'hyzomc@2023 ', 6, '10.173.101.36', 3306, 'cmbas', 'yncm', 'cmbas@2023', '1', 400);


上海为例
INSERT INTO t_cfg_cserverinfo
(lsc_id, lsc_name, csvrip, csvrport, clogusrname, clogusrpwd, dbtype, dbsvrip, dbsvrport, dbname, dblogname, dblogpwd, access_device_id, protocol_id)
VALUES(431, '上海-接入', '10.1.203.38', 8272, 'hyzomc', 'hyzomc@2023 ', 6, '10.1.203.120', 3306, 'root', 'cinterdb_gd', 'xxx', '1', 400);



如果使用的是未加密的密码，这里需要多一步加密
	调用configmanagement模块进行加密：
		就是到对应环境的configmanagement服务里面执行【可以在nacos里面找】
		lscid则为上述创建时创建的lscid
	curl --location 'http://localhost:13563/v1/cserverinfo/encryptedInfoByLscId?lscId=571'
```

# 步骤4

## 根据表插入配置nacos中配置yml文件

```
这里主要是对nacos中的C接口配置yml的配置【可以直接新增一个yml，这里的yml作用就是用于C接口启动时读取】


以上海为例
	在nacos配置列表里面，找到对应省份，data id输入cinter
	找到：ms-cinterface-service-gd-new.yml 
		需要配置的参数
			server
				port								为C服务所在服务器，启动时的端口[配置时需要先到服务器看端口是否用过] - 即服务列表中的port就是配置列表yml中的port
													目前上海这个起在10.1.203.121上面，需要在上面确保端口没有占用
			app
				client[接入时配置]
					id								为t_cfg_cserverinfo的lsc_id
					province_name					为区分接入的省份[广东-卓望 即用于后续写入t_cfg_site_mapping表的provice_name]
					dbInitlscId						为t_cfg_cserverinfo的lsc_id
					lscIdConfig						为t_cfg_cserverinfo的lsc_id
					autoCreateIndexProvinceId		为接入省份的ID[目前是接入广东的 -- 因此是01-01]
				server[接出时配置]
					clientId
			kafka.topic.cinterface_getPointDataRequest		Kafka实时数据topic修改【最后的两个数字修改为lsc_id的前两位数字】
			kafka.topic.cinterface_updDeviceModel			Kafka实时数据topic修改【最后的两个数字修改为lsc_id的前两位数字】
以内蒙为例


```

# 步骤5

## C接口部署与启动

```
docker run 
	--name cinterface-service-yunnan 
	--net host  
	--env spring.cloud.inetutils.preferred-networks=192.168.0.55 
	--log-driver=json-file 
	--log-opt max-size=30m 
	--log-opt max-file=3 
	--env ENV_NACOS=10.1.5.109:8848 
	--env ENV_TYPE=yunnan 
	--env ENV_APP_NAME=cinterface-service-yunnan 
	--env ENV_NACOS_PASSWORD=r2G%zwoCj#Oz 
	-v /tmp/logs/rbac:/opt/data/logs/ 
	-d 
	10.1.6.34:8080/spider/yunnan/cinterface-service:spider1.0.0.0_kernelYunNan_SYT_149
	
	
重要参数解析
	--env ENV_NACOS=10.1.5.109:8848 														这里为nacos的ip和端口
	--env ENV_TYPE=sc-dev 																	这里为nacos的命名空间即环境
	--env ENV_APP_NAME=cinterface-service-yunnan											这里为nacos的配置列表中对应环境C接口的配置
	--env ENV_NACOS_PASSWORD=r2G%zwoCj#Oz 													这里为nacos的登录密码
	-v /tmp/logs/rbac:/opt/data/logs/ 														卷挂载（日志持久化）
	-d																						后台运行
	10.1.6.34:8080/spider/yunnan/cinterface-service:spider1.0.0.0_kernelYunNan_SYT_149		这里是C接口的镜像，在cicd流水线中找
																							这里是接入哪个省份就需要拉哪个省份的
	
	注意ENV_APP_NAME对应关系
		ENV_APP_NAME=cinterface-service-yunnan对应的是ms-cinterface-service-yunnan.yml
		
		
实例【cicd - 流水线 - gemc:kern - GEMC_cinterface-service - 注意拿最新的镜像】：
docker run 
	--name cinterface-service-sc-new 
	--net host 
	--log-driver=json-file 
	--log-opt max-size=30m 
	--log-opt max-file=3 
	--env ENV_APP_NAME=cinterface-service-gd-new 
	--env ENV_NACOS=10.1.203.120:8848 
	--env ENV_TYPE=sc-dev 
	--env ENV_NACOS_PASSWORD='D&V2HR43TutFjf%aKqk'  
	-v /tmp/logs/configmanagement:/opt/data/logs/ 
	-d 10.1.6.34:8080/cicd-public-49/cinterface-service:1.0.3.2_22_20250807030001
```

# 步骤6

## 定时任务启动

```
这里主要在C接口服务器里面执行，执行了定时任务后续才会有实时数据写入和告警
重点注意：每次重启了C接口服务，都需要执行一次定时任务


以上海为例【接入广东lsc】
	目前C接口所属服务器【10.1.203.121里面】，需要到该服务器下执行
	然后端口是nacos配置文件中，该C接口配置文件定义的port
		curl --location  'http://10.1.203.121:8272/v1/cinterface/startSyncTimer'
```

# 步骤7

## 站点映射配置

| 数据库属性     | 解释                                           |
| -------------- | ---------------------------------------------- |
| provice_name   | 省份，对应配置文件app.client.province_name     |
| city_name      | 市                                             |
| area_name      | 区                                             |
| site_type      | 接口类型 1:网络云2:核心机楼                    |
| interface_type | 接口类型 1:C接口；2:资管                       |
| lsc_id         | 站点Id                                         |
| lsc_name       | 一级SC站点名                                   |
| mapping_name   | 映射外部系统站点名，对应中间库m_site的siteName |
| mark           | 备注                                           |

```
这里主要是对动环库中t_cfg_site_mapping表的站点 与 模拟器上的站点做映射


以上海【接入广东】为例
	provice_name			为步骤4、C接口启动读取的yml配置里的province_name【用于区分是哪个省份接入的】		
	city_name				为步骤4、C接口启动读取的yml配置里的province_name【下的城市】     	--这个的作用
	area_name				为步骤4、C接口启动读取的yml配置里的province_name【下城市的区域】      --这个的作用
	lsc_id					为上海动环系统创建的省份下的城市的区下的站点  的 precinct_id
	lsc_name				为上海动环系统创建的省份下的城市的区下的站点  的 站点名
	mapping_name			为中间库m_site中的站点名【与步骤2中写入的m_site的siteName】




INSERT INTO t_cfg_site_mapping
(province_name, city_name, area_name, site_type, interface_type, lsc_id, lsc_name, mapping_name, mark)
VALUES('广东', '广州市', '白云区', 2, NULL, '01-01-17-02-29', '广州白云区矮岭西街一巷16号', '广州白云区矮岭西街一巷16号', NULL);

```

# 步骤8

## 站点同步【也叫稽核同步】

```
这里主要是实现把中间库站点和机房、设备、测点等配置，同步到动环过去


以上海为例
	首先是在空间里，创建了新的市、市下又创建了新的区、市里面创建了新站点【站点下做任何操作、通过同步来实现】
	方法1【按站点稽核同步 -- 目前用的这个】：
		注意点：
			ip是C接口所在服务器【目前是10.1.203.121】
			port是C接口配置yml中的port【目前是8272】
			siteId：站点id【对应页面创建的站点id  -- 目前是上海市下的测试站点】
		接口位置：
			/v1/cinterface/compareAndSyncBySite（get请求）
			根据某个站点进行稽核同步基本配置数据
		参数详情
			operateUser：操作者（任意）
			siteId：站点id（对应页面创建的站点id）
			justCompare：是否只进行比较，true，只进行比较；false 比较并进行同步配置数据【即把站点下所有信息同步过去】
		例子
			curl --location 'http://10.12.12.184:8180/v1/cinterface/compareAndSyncBySite?operateUser=chw-0919&siteId=01-24-09-02-66-15&justCompare=false'
			
			curl --location 'http://10.1.203.121:8272/v1/cinterface/compareAndSyncBySite?operateUser=chw-0919&siteId=01-24-09-02-66-15&justCompare=false'
			
	方法2【手工稽核同步】：
		注意点：
			ip是C接口所在服务器【目前是10.1.203.121】
			port是C接口配置yml中的port【目前是8272】
			siteId：站点id【对应页面创建的站点id  -- 目前是上海市下的测试站点】
		接口位置
			/v1/cinterface/syncBycommand（post请求）
			稽核全部站点同步基本配置数据。
		参数详情
            precinctId：省份id,例如陕西为01-24；
            optPerson：操作者；
            siteId：可以为空，保存到日志表，没意义。
		例子
			http://10.12.12.184:8180/v1/cinterface/syncBycommand
			{ "precinctId": "01-24", "optPerson": "chw", "siteId": "" }
```

# 步骤9

## 验证

```
根据“综合监控-监控视图”，搜索站点，检验对应站点的设备测点数据是否同步上来
```

# 步骤10

## 告警数据同步

```
步骤1：
	C接口读取中间库D_ACTIVEALARM表的活动告警数据进行解析
		作为生产者向kafka上报告警数据（topic:spider_binterface_alarm）
		alert模块作为消费者从kafka拉取最新告警进行消费保存到活动告警表alert_alerts
		消警后进入alert_alerts_his
	
	
步骤2：
	（1）需要先同步基本配置表，D_ACTIVEALARM配置的测点需已存在
	（2）需要配合configmanagement模块和alert模块进行调用
	（3）测点需已标准化才能上传到kafka,由alert模块进行消费


步骤3：
	执行频率：
		通过配置文件app.client.alarmSyncCron进行修改定时任务的执行频率  【即步骤4中C接口服务启动时读取的yml配置文件】
	通过步骤六的定时任务
		ip为C接口服务器的ip，端口为C接口启动时读取的nacos里对应的C接口服务配置yml
		curl --location  'http://10.1.203.121:8272/v1/cinterface/startSyncTimer'
		
步骤4：
	验证：
		查看“告警管理-视图-活动告警”，检查告警数据是否同步上来
```

# 步骤11

## 历史数据同步

```
步骤1：
	C接口从D_SIGNALH表读取数据，同步到ES历史数据，解析并保存到elasticsearch的索引里（索引名：fsu_yyyyMMdd_省份ID）
	
	
步骤2：
	（1）需要先同步基本配置表，D_SIGNALH配置的测点需已存在；
	（2）需要配合configmanagement模块进行调用
	
步骤3：
	（1）执行频率：通过配置文件app.client.signalSyncCron进行修改定时任务的执行频率		 【即步骤4中C接口服务启动时读取的yml配置文件】
	（2）通过步骤六的定时任务
		ip为C接口服务器的ip，端口为C接口启动时读取的nacos里对应的C接口服务配置yml
		curl --location  'http://10.1.203.121:8272/v1/cinterface/startSyncTimer'
		
步骤4：
	验证
		根据“报表管理-报表-性能数据报表-遥测量历史数据报表”，搜索对应站点和时间，检查对应的历史数据是否同步上来
```

# 步骤12

## 实时数据验证

```
步骤1：
	根据步骤6的curl开启tcp客户端，连接t_cfg_cserverinfo表的tcp服务端
		curl --location  'http://10.1.203.121:8272/v1/cinterface/startSyncTimer'
			即C接口作为客户端、C接口模拟器作为服务端【C接口模拟器提供数据上来  -- 通过一个端口来监听】
步骤2：
	查看监控视图，等待10s后，看是否能采集到“当前值”和“采集时间”
	获取数据时间每10s会刷新一次，如果超过10s则代表实时数据获取存在问题
	如果采集时间距离当前时间很久，则代表为es的历史数据
```









# 常见问题

```
操作注意项
	01、配置C接口配置yml中的端口、需要先到C接口服务器中确保端口没有被使用【lsof -i:端口】
	02、启动模拟器前，config配置里面的socket_port设置为C接口启动时的端口
	03、启动模拟器前，config配置里面的http_port为C接口模拟器的端口、需要确保C接口模拟器所属服务器下没有使用到该端口【lsof -i:端口】
	04、启动模拟器之后，需要查看对应模拟器日志【检查是否启动成功  -- 页面是否能正常访问】
	05、启动模拟器之后、需要在C接口模拟器所属服务器下，白名单里面添加新的端口【即要访问该连接的主机，授权该端口】
	06、启动模拟器之后、需要在C接口模拟器所属服务器下，白名单里面添加新的端口【即要访问该连接的主机，授权该端口】
	07、启动模拟器之后、需要在C接口模拟器所属服务器下，给C接口服务器添加白名单【端口为scoket_port,C接口能与服务器通信，即连接tcp服务端】
	08、C接口服务启动后、需要查看对应容器的日志【检查是否启动成功  -- docker logs --tail 400 -f 容器id】
	09、每次修改动环库中的t_cfg_cserverinfo，需要重新启动C接口服务【如果不重启则不生效  -- docker restart 容器id】
	11、每次修改动对应环境c接口配置的port或其他参数，需要重新启动C接口服务【如果不重启则不生效  -- docker restart 容器id】
	10、每次重新启动C接口服务，都需要重新执行定时任务
	

端口与ip配置准确性
	1、C接口中的config.py 的 socket_port【C接口服务器的】,http_port
	2、配置表中的csvrip，csvrport	  【C接口模拟器的ip、C接口服务器的port】
	3、nacos中的port				【C接口服务器的】
	4、定时任务和站点同步的ip和port   【C接口服务器的】
	


C接口服务日志-站点重复
	1、是t_cfg_site_mapping中mapping_name重复了，删除就可以


C接口服务日志-报文开头不正常
	1、是ip和应用不对应


C接口服务日志-channel通道null
	1、ip不对应
	2、没有启用定时任务


C模拟器启动后日志-already报错
	1、可能端口重复使用问题


```







































# 方式2

环境变量：全都是nacos的相关配置信息

shanxi-cicd：是nacos中对应环境的命名空间

![image-20250908110114731](assets/image-20250908110114731.png)
