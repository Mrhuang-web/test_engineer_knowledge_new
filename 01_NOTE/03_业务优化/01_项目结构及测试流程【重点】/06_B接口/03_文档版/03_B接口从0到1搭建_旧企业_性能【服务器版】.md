# 前提事项

## 前提了解

```
B接口服务分布
	1、B接口拆分成 client, server, dataHandle 三种启动模式
	
	client端的职责【页面会每10s进行current接口请求 - 下发到B接口，B接口向fsu】：
		接收上层的请求（比如currentmonitor调用的获取实时数据，下发指令），并完成向FSU的请求。
	server端的职责【其实就是接口数据的上传，到B接口进行处理显示到页面啥的】：
		接收FSU上报的数据，比如注册数据，配置数据，告警数据等
	dataHandle端的职责：
		完成数据持久化。
		比如：
			从client端收到FSU报上来的实时数据后，
			client端把数据转发到kafka, 
			再由dataHandle端监听并消费kafka的数据，并完成入库（写redis, ES）
```



```
原来“一堆FSU挤在一起干活”
现在“一个一个排队，谁干完谁再领新任务”，并且“加个中间人（Nginx）分流，避免一个人累死”
```

![image-20250921020641577](../00_插图/03_B接口从0到1搭建_旧企业【服务器版】.assets/image-20250921020641577.png)

| 角色           | 原来怎么做                      | 现在怎么做                                                   | 记住关键词       |
| -------------- | ------------------------------- | ------------------------------------------------------------ | ---------------- |
| **Client**     | 每来一个请求就去找FSU，瞬间爆炸 | 5秒内的请求合并成1次，结果扔Kafka<br />（消费者：dataHandle） | **“合并请求”**   |
| **Server**     | 1个节点扛4000个FSU，CPU哭       | Nginx做“门卫”，轮流分给2+节点                                | **“分流”**       |
| **dataHandle** | 定时任务一次塞150个FSU，卡死    | 1个FSU一条消息，干完再领                                     | **“单线程排队”** |

```
client
	client端并不直接处理数据
		1、调用“v1/currentmonitor/getMeasureVal”接口，查看指令合并情况
		2、N秒是可配置项，对应的配置项是：request.merge.interval:5    【nacos的binter配置文件中】
		3、合并就是多交请求共用一次的结果（5秒内请求过，不请求，返回的数据在5秒内，不请求）
		
    
dataHandle（定时任务-fsu状态检测）
	B接口内部的定时任务之一：
		FSU状态检查，即每5分钟向所有的FSU发起一次状态检查
        之前的做法：
            把所有的FSU加载到内存，然后按150个FSU一个包，放到KAFKA里面
            再由消费者完成KAFKA状态检测工作
        修改之后：
            1）改为一个FSU一条消息推到kafka
            2）如果当前有正在处理中的FSU，则不重复推到kafka里面，避免无用的状态检测请求。 
            3）定时任务包的大小配置：fsu_total_per_msgpack:1 （ms-binterface-prod.yml 中配置）
            4）添加判断当前是否有正在检测中的FSU，如果有，则不重复添加。
            5）其它逻辑不变
            定时任务-历史数据同步等任务
                时任务分发改造为1个fsu对应一个 B接口的任务包大小都是同一个配置项
                1）定时任务包的大小配置：fsu_total_per_msgpack:1 
                    （ms-binterface-prod.yml 中进行配置）
     kafka消费实时数据响应结果 新增，消费持久化 
     	1）获取设备实时数据时，CLIENT端和FSU进行交互，FSU把设备测点数据响应给CLIENT端
     	2）CLIENT端对测点数据并不直接操作，而是把接收到的数据推到KAFKA
     	3）data 模式的B接口监听KAFKA主题，然后消费数据，并解析入库（写redis, ES）
     	
        	


server FSU数据上报 
    1）之前只有一个B接口节点接收超过4000个FSU上报的数据，节点性能出现瓶颈，
    2）现使用2个或以上的节点进行接收FSU数据上报
    	3）需要接入Nginx进行代理
    	4）FSU配置上报的地址为 Nginx监听的地址。 
    		1、在ng监听28080端口，FSU把数据上报，先通过NG的 28080端口，
    			然后再由NG路由颁发给两个server 模式启动的B接口
			2、通过上报注册数据 / 配置数据，可看到路由到2个 server模式的B接口


指令下发 
	1）client端的B接口接收指令下发，其它模式的按理不接收上层请求。
```



## 文件准备

- B接口镜像选择【目前有GEMC - 即广东的，SNEMS - 即陕西的】
  - 通过进入CICD、流水线搜索binter
  - 选择对应环境B接口【通过流水线名称跳转；或构建详情跳转】即可查看对应镜像
  - 同时注意：需要把端口改成8080
  - ![image-20250921004113333](../00_插图/03_B接口从0到1搭建【服务器版】.assets/image-20250921004113333.png)
- nginx
- kafka - zookeeper
- ftpproxy
- fsumanager

```
广东为例
 
文件准备
	B接口镜像选择【目前有GEMC - 即广东的，SNEMS - 即陕西的】
		
	

文件部署注意事项
	需要吧一个binter镜像拆分成三个子节点
	还需要有一个ftp的镜像
	然后kafka，可以重启，或是连已有的【怎么连？】
	然后ng代理配置
		需要找到ng对应位置，参考已有的b接口的ng配置是怎么样的
		ps -ef|grep nginx
```



```
在10.1.4.193启动【测性能时，需要单独在一个服务器里面搞】
	部署前准备内容【除了前面四个是容器，后面两个是直接运行在虚拟机无需建立容器】
		binterface-service-server-p1、
		binterface-service-client-p1、
		binterface-service-data-p1、
		ftpproxy-service-p1、
		kafka
		zookeeper
		
然后模拟器config.py配置
	可以把b接口的ip换成  【cicd对应接口服务的node】
	
当时改了最新包
talnet   【直接在cicd的终端就可以】
```





## 服务部署

```
服务启动
    docker save -o /home/sudoroot/new_binterface.tar cd0d7839534d
    scp -r /home/sudoroot/new_binterface.tar sudoroot@10.12.12.184:/home/sudoroot/new_binterface
    docker load -i /home/sudoroot/new_binterface/new_binterface.tar
    docker tag cd0d7839534d binterface-service
```

```
B接口启动脚本 (CLIENT模式）

	docker run --name binterface-service-client-p1 --net host  --log-driver=json-file --log-opt max-size=30m --log-opt max-file=3 --env SERVER_PORT=18181 --env ENV_EUREKA=http://10.12.12.184:8761/eureka/ --env spring.cloud.inetutils.preferred-networks=10.12.12.186 --env ENV_CONFIG_IP=10.12.12.184 --env ENV_CONFIG_PORT =18888 --env ENV_TYPE=prod --env RUN_MODE=client  -v /tmp/logs/binterface-service-new:/opt/data/logs/ -d binterface-service:latest
```

```
B接口启动脚本 (SERVER模式 或 DATA）

	docker run --name binterface-service-dataHandle-p1 --net host  --log-driver=json-file --log-opt max-size=30m --log-opt max-file=3 --env SERVER_PORT=18185 --env ENV_EUREKA=http://10.12.12.184:8761/eureka/ --env spring.cloud.inetutils.preferred-networks=10.12.12.186 --env ENV_CONFIG_IP=10.12.12.184 --env ENV_CONFIG_PORT=18888 --env ENV_TYPE=prod --env RUN_MODE=dataHandle --env APPLICATION_NAME=binterface-service-dataHandle  -v /tmp/logs/binterface-service-new:/opt/data/logs/ -d binterface-service:latest
```

```
| 启动模式-节点 | 端口 | RUN_MODE |
| —————— | —————— | —————— |
| client-p1 | 18081 | client |
| client-p2 | 18082 |client |
| server-p1 | 18083 | server |
| server-p2 | 18084 | server |
| datahandle-p1 | 18085 | datahandle |
| datahandle-p2 | 18086 |datahandle|
```

## 机房准备

```
新建500个机房、每个机房接入1个FSU
    1、机房创建用接口创建，
    2、设备信息直接插入数据库
```

```
# encoding:utf-8
"""
@CreateTime:      2024/1/30 16:12
@Author:          Tsuiguangchun
@FileName:        make_room_devices.py
@IDE_SoftWare:    PyCharm
@description:    
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
"""
import TestEnv
from Common.all_excelCase_file_path import load_excel_data
import os
import requests
from asptest.common.mysqlpool import MySQLHelper
ROOT_PATH = os.path.dirname(os.path.abspath(__file__))
work = os.path.join(ROOT_PATH, "Params", "upload", "room_name.csv")
conn_obj = MySQLHelper(TestEnv.ServerConfig['db_pas_sx'])
def make_room():
    file = open(file=work, mode='r', encoding='utf-8')
    data = file.read()
    # print(f"data:{data}")
    url = "http://10.12.12.184:8280/spider/web/v1/configManagement/saveStationPrecinct?namespace=alauda"
    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json",
        "head_orgAccount": "alauda",
        "head_userName": "alauda"
    }
    for name in data.split('\n'):
        print(f"开始创建机房：{name}\n")
        data = {
            "upPrecinctId": "01-24-04-16-01",
            "precinctId": "",
            "precinctName": f"{name}",
            "areaCode": "",
            "stationTypeName": "传输节点",
            "roomKind": "5",
            "airType": 1,
            "x": "",
            "y": "",
            "altitude": "",
            "runType": "0",
            "leader": "",
            "leaderName": "",
            "leaderPhone": "",
            "resourceCode": "",
            "address": "",
            "description": "",
            "precinctKind": 5,
            "scene": "",
            "accessType": 1,
            "namespace": "alauda"
        }
        response = requests.post(url=url, headers=headers, json=data).text
        print(response)
def make_fsu_device(ip="10.12.12.186", port=8080):
    precinct_id_sql = "SELECT precinct_id FROM t_cfg_precinct WHERE precinct_id like '01-24-04-16-01-%';"
    precinct_id_list = conn_obj.select(sql=precinct_id_sql)
    for pd in range(len(precinct_id_list)):
        # print(precinct_id_list[pd][0])
        device_id = "00" + str(int("00813006000001768642") + pd)
        device_code = str(202400002 + pd)
        device_name = f"2024年{'%04d'%pd}FSU"
        precinct_id = precinct_id_list[pd][0]
        access_device_id = "001" + str(int(device_code))
        insert_device_sql = f"INSERT INTO t_cfg_device(`lsc_id`, `device_id`, `device_name`, `precinct_id`, `device_index`, `device_cid`, `isdel`, `device_model`, `device_kind`, `sub_device_kind`, `device_type`, `sub_device_type`, `belong_device_id`, `device_code`, `manufacturer_id`, `device_use_state`, `purchase_time`, `use_time`, `use_years`, `update_time`, `install_site`, `device_principal`, `x`, `y`, `manufacturer_name`, `description`, `version`, `locate_ne_status`, `resource_code`, `leader_phone`, `resource_origin`, `resource_name`, `index_seq`, `use_end_time`, `rated_power`, `load_power`, `device_mark`, `unit`, `rectifierModuleNumber`, `singleModuleRatedCurrent`, `province_index`, `related_rackpos`, `access_type`, `actual_start_time`, `join`) VALUES ('713', '{device_id}', '{device_name}', '{precinct_id}', 1, NULL, 000, NULL, 13, NULL, 76, 3, NULL, '{device_code}', 1617, 1, NULL, NULL, NULL, '2024-01-30 11:40:14', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 8528903, NULL, NULL, NULL, NULL, NULL, 0, 0, 124, NULL, NULL, NULL, NULL)"
        insert_fsu_sql = f"INSERT INTO t_cfg_fsu(`device_id`, `access_device_id`, `address`, `listen_port`, `up_fsu_id`, `up_link_port`, `net_type`, `net_info`, `fsu_state`, `register_server`, `udp_port`) VALUES ('{device_id}', '{access_device_id}', '{ip}', {port}, NULL, NULL, 0, NULL, 0, '1', NULL)"
        conn_obj.insertone(sql=insert_device_sql)
        conn_obj.insertone(sql=insert_fsu_sql)
        print(f"已经插入：{precinct_id}")
    # for precinct_id in precinct_id_list:
    #     print(precinct_id_list.get[0])
    # pass
make_fsu_device()
3、然后导出fsuid,设备名称数据，
4、读取出来，参数化遍历传入调用准备数据

# -*- coding:utf-8 -*-
from module import *
from openpyxl import Workbook
from openpyxl import load_workbook
import random
# fsuid = '19000001000000'
fsuid = "8000017900"
"""清除脚本
SET @fsuid = '265224658376462';
DELETE FROM signals WHERE fsuid=@fsuid;
DELETE FROM device WHERE fsuid=@fsuid;
DELETE FROM fsu WHERE fsuid=@fsuid;
"""
def load_xls_fsu(fsu_deviceid="20240000000005",fsu_name="test"):
    # global fsu_deviceid
    # fsu_deviceid = str(random.randint(100100000000608, 999999999999999))
    fsu_deviceid = fsu_deviceid
    wb = load_workbook('./fsu_data.xlsx')
    ws = wb['fsu']
    result_list = []
    for row in ws.iter_rows(min_row=2):
        # fsuid = row[0].value
        fsuid = fsu_deviceid
        fsuname = fsu_name
        # fsuname = row[1].value
        fsuver = row[2].value
        siteid = row[3].value
        sitename = row[4].value
        roomid = row[5].value
        roomname = row[6].value
        interval = row[7].value
        m = row[8].value
        # print('%s %s %s %s %s %s %s %s' % (fsuid, fsuver,siteid, sitename,roomid,roomname,interval, m))
        if fsuid != 'None' and m != 'None':
            result_list.append([fsuid, fsuname, fsuver, siteid, sitename, roomid, roomname, interval, m])
    return result_list
def load_xls_device(fsu_deviceid="20240000000005"):
    # global fsu_deviceid
    wb = load_workbook('./fsu_data.xlsx')
    ws = wb['device']
    result_list = []
    for row in ws.iter_rows(min_row=2):
        m = row[0].value
        fsuid = row[1].value
        deviceid = row[2].value
        if deviceid == '100100000000076':
            deviceid = fsu_deviceid
        devicename = row[3].value
        devdescribe = row[4].value
        siteid = row[5].value
        sitename = row[6].value
        roomid = row[7].value
        roomname = row[8].value
        devicetype = row[9].value
        devicesubtype = row[10].value
        model = row[11].value
        brand = row[12].value
        ratedcapacity = row[13].value
        version = row[14].value
        beginruntime = expr_none(row[15].value)
        confremark = expr_none(row[16].value)
        # print('%s %s %s %s %s %s %s %s %s %s %s %s %s %s %s %s %s' % (m,fsuid, deviceid,devicename, devdescribe,siteid,sitename,roomid,roomname,devicetype,devicesubtype,model,brand,ratedcapacity,version,beginruntime,confremark))
        result_list.append(
            [m, fsuid, deviceid, devicename, devdescribe, siteid, sitename, roomid, roomname, devicetype, devicesubtype,
             model, brand, ratedcapacity, version, beginruntime, confremark])
    return result_list
def load_xls_signal(fsu_deviceid="20240000000005"):
    # global fsu_deviceid
    wb = load_workbook('./fsu_data.xlsx')
    ws = wb['signal']
    result_list = []
    for row in ws.iter_rows(min_row=2):
        m = row[0].value
        deviceid = row[1].value
        if deviceid == '100100000000076':
            deviceid = fsu_deviceid
        Type = row[2].value
        ID = row[3].value
        SignalName = row[4].value
        SignalNumber = row[5].value
        AlarmLevel = row[6].value
        if AlarmLevel is None:
            AlarmLevel = '4'
        Threshold = row[7].value
        NMAlarmID = expr_none(row[8].value)
        # print('%s %s %s %s %s %s %s %s %s' % (m, deviceid,Type,ID,SignalName,SignalNumber,AlarmLevel,Threshold,NMAlarmID))
        result_list.append([m, deviceid, Type, ID, SignalName, SignalNumber, AlarmLevel, Threshold, NMAlarmID])
    return result_list
def expr_none(somestr):
    if somestr == None:
        return ''
    else:
        return somestr
def add_fsu(fsu_xls_record):
    fsu = Fsu()
    fsu.fsuid = fsu_xls_record[0]
    fsu.fsuname = fsu_xls_record[1]
    fsu.username = fsu_xls_record[0]
    fsu.password = fsu_xls_record[0]
    fsu.fsuip = '10.1.24.7'
    fsu.fsumac = '01-01-01-01'
    fsu.fsuver = fsu_xls_record[2]
    fsu.siteid = fsu_xls_record[3]
    fsu.sitename = fsu_xls_record[4]
    fsu.roomid = fsu_xls_record[5]
    fsu.roomname = fsu_xls_record[6]
    fsu.tfsustatus_cpuusage = '10'
    fsu.tfsustatus_memusage = '20'
    fsu.tfsustatus_harddiskusage = '30'
    fsu.interval = fsu_xls_record[7]
    session.add(fsu)
    session.commit()
def add_device(fsuid, fsuname, device_xls_record):
    device = Device()
    device.fsuid = fsuid  # ??fsuid, ??excel??????excel????
    device.deviceid = device_xls_record[2]
    device.devicename = device_xls_record[3]
    device.siteid = device_xls_record[5]
    device.roomid = device_xls_record[7]
    device.sitename = device_xls_record[6]
    device.roomname = device_xls_record[8]
    device.devicetype = device_xls_record[9]
    if device.devicetype == 76:
        device.devicename = fsuname  # 对于type=76的，设备名称改为fsu的名称
    device.devicesubtype = device_xls_record[10]
    device.model = device_xls_record[11]
    device.brand = device_xls_record[12]
    device.ratedcapacity = device_xls_record[13]
    device.version = device_xls_record[14]
    device.beginruntime = device_xls_record[15]
    device.devdescribe = device_xls_record[4]
    device.confremark = device_xls_record[16]
    session.add(device)
    # session.commit()
def add_signal(fsuid, deviceid, signal_xls_record):
    signal = Signals()
    signal.fsuid = fsuid
    signal.deviceid = deviceid
    signal.signalsid = signal_xls_record[3].zfill(6)  # ???6??,???mete_code
    signal.type = signal_xls_record[2]
    signal.signalname = signal_xls_record[4]
    # print(signal_xls_record[5])
    signal.signalnumber = str(signal_xls_record[5]).zfill(3)  # ???3?????000
    signal.alarmlevel = signal_xls_record[6]
    # signal.thresbhold =  signal_xls_record[7]
    # alert服务在收到告警时会去查测点的门限值，并转为数值类型，如果为空，则转换会失败，这里强制改成可转值的值
    signal.thresbhold = '1'
    signal.nmalarmid = signal_xls_record[8]
    signal.measuredval = ''
    signal.setupval = ''
    signal.status = ''
    signal.time = '2023-10-13 00:00:00'
    session.add(signal)
    # session.commit()
def test(fsu_deviceid,fsu_name):
    # global fsuid
    # print queryFsu(fsuid)
    # if queryFsu(fsuid) == None:
    #    add_fsu()
    fsu_list = load_xls_fsu(fsu_deviceid,fsu_name)
    device_list = load_xls_device(fsu_deviceid)
    signal_list = load_xls_signal(fsu_deviceid)
    for fsu_record in fsu_list:
        fsuid = fsu_record[0]
        fsuname = fsu_record[1]
        print(queryFsu(fsuid))
        if queryFsu(fsuid) == None:
            m_idx = fsu_record[8]
            add_fsu(fsu_record)
            print(fsu_record)
            dev_list = [li for li in device_list if li[0] == m_idx]
            for device_record in dev_list:
                devid = device_record[2]
                add_device(fsuid, fsuname, device_record)
                print(device_record)
                sig_list = [li for li in signal_list if li[0] == m_idx and li[1] == devid]
                for signal_record in sig_list:
                    sigid = signal_record[1]
                    add_signal(fsuid, devid, signal_record)
                    print(signal_record)
    session.commit()
if __name__ == "__main__":
    # test()
    file = '/Users/xuguangchun/Documents/b接口.csv'
    data = open(file=file, mode='r', encoding='utf-8').read()
    for d in list(data.split()):
        # print(d)
        fsuid = list(d.split(','))[0]
        fsuname = list(d.split(','))[1]
        # print(fsuid, fsuname)
        test(fsu_deviceid=str(fsuid),fsu_name=str(fsuname))
```

脚本设置

```
1、jmeter配置版本5.5
2、安装路径查询：echo $JMETER_HOME ——>/opt/apache-jmeter.5.5/
3、工作节点:10.12.12.186, 10.12.70.59
4、节点sever启动：切换到安装路径的bin目录下执行下方命令：
    cd /opt/apache-jmeter5.5/bin/
    [root@dh186 ~]# 
    ./jmeter-server -Djava.rmi.server.hostname=10.12.12.186
    ./jmeter-server -Djava.rmi.server.hostname=10.12.70.59



5、控制点需要配置工作节才能监听和下发
	工作节点server感觉不稳定，不知道是不是jdk版本不一致的问题，
	会出现连接超时或者服务自动停止2024-02-05 18:04:34,097 ERROR o.a.j.e.DistributedRunner: 
	The following remote engines have not started:[10.12.12.186:1099]
6、当前接口服务启动情况如下：10.12.12.184是P2节点，10.12.12.186是P1
7、目前注册上报用测试-FSU模拟器接口注册、配置上报操作，但是通过分布式多节点并发时，查看端口，一堆服务阻塞显示waitting，接口无响应，需要kill掉重新启动服务才能恢复。
8、分布式压测不适用fsu上送数据,原因：
	控制🐔分发slave节点做一样的事,而b接口是实现高效消费，不做重复事件，因此不适用分布式。
	比如控制点+2slave工作节点，100个线程，分发出去也就是300个线程，200个线程是做一样的事情。
	适合单机击压测，但是jmeter 单机压测能力是上限的，并不能很好到的压测出性能的B接口瓶颈。
	从某种角度看，对于b接口业务上逻辑重复数据是无意义的，但是也会给服务器产生压力类似攻击。
9、B接口改造之前超过4000个FSU上报的数据，节点性能出现瓶颈，
	因此本次改造压测需要在此之上，然后不断增量式压测来测试B接口性能瓶颈。

```

  
