# 01总结

```

```





# 02补充

```
提测内容：
	涉及表：
	his_data_collect_device_metecodes


涉及范围：
服务：
1、currentMonitor（修改）
2、datacollection（修改）
3、distribute-service（新增）
4、binterface-service-client（修改）


配置：
1、currentMonitor
    sendToDistribution: true   
    # 实时数据请求分发，将 kafka 请求分发到 distribute-service 服务，
    当为false的时候，走之前的逻辑

2、datacollection
sendToDistribution: true  # 实时数据请求分发，将 kafka 请求分发到 distribute-service 服务，当为false的时候，走之前的逻辑
saveToEsViaKafka: true    # 之前datacollection服务采集是阻塞请求，现在改为走kafka异步处理
save.to.mysql: true       # 当 sendToDistribution=true的时候，数据会发送到kafka, 上海SC，会将采集的结果写到mysql

3、distribute-service
runMode: binterface     # distribute服务适用于B接口与C接口，以上海SC为例，采用的均是B接口，则如此配置，


脚本：
【测试环境已执行】https://gitsz1.aspirecn.com/spider/gemc/-/blob/develop_distribution/gemc/bin/dbscript/GEMC1.0.8.0/ddl/定时任务数据设备测点集合_ddl_20251120.sql


此次改造功能为解决以下问题：
（1）当发起大量的性能数据采集时，会对实时数据查询（监控视图）造成影响
（2）采集较慢或无法采集的设备会造成阻塞，导致积压，能够正常采集的设备也无法较快响应。


主要逻辑与处理方式：
1、对采集设备进行打标签处理，给设备打标识：快，慢，差
2、新增采集调整策略（采集降级）
	当队列里面达到500个设备，不再接收 tag=差 的设备，即这类型设备将丢弃掉
	当队列里面达到700个设备，不再接收 tag=慢 的设备，即这类型设备将丢弃掉
	当队列里面达到1000个设备，不再接收定时采集任务，优先保证实时监控请求的任务
3、快，慢，差计算标准：
	（1）快：采集快慢的标准是按项目时间需求来计算的（比如5分钟要完成2000个，那么快的标准就是： 5*60*1000 / 2000 = 150ms， 即150ms内完成数据采集的设备，就是快的设备）
	（2）慢：快 * (1~3)，介于快与差之间
	（3）差：> 快 * 3，即450ms
4、重试机制：当出现采集慢的时候，等待采集的队列会被塞满，当队列满了，尝试5次（重试时间间隔：3s,10s,30s,1min,3min）如果都失败，放回原队列
5、丢弃策略：当队列中等待设备>700，5分钟内采集过的设备，丢弃。
6、请求合并：新请求的设备，如果此设备在采集队列中（因为前面堵塞，导致还没有下发请求，那应该将此设备进行请求合并）
7、请求去重：在5秒内，重复请求的设备，去重处理，降低采集频率。



测试范围：
1、监控视图——设备实时数据查询（保证原有功能可用）
2、实时数据报表——设备实时数据查询（保证原有功能可用）
3、定时任务采集——正常采集，入库es（保证原有功能可用）
4、采集降级——出现采集慢/不可用设备，就当对此部分设备进行降级处理，即无法采集/采集慢的设备不能影响其他正常采集速度的设备（新增）
5、“主要逻辑与处理方式”中提及到的优化项
```



```
补充：
	1、his_data_collect_device				（设备分组，即每个任务需要去采集的设备有哪些）
	2、his_data_collect_device_metecodes		（测点分组，即每个任务下每个设备需要采集的测点有哪些）


	请求方式：
		1、用实时监控接口		（200个设备，每个设备5个测点，等于1000）
		2、使用定时采集任务


	目前有两个流程
		一个是实时接口
			监控视图  													定时采集

			current下发													有定时采集

			会到spider currentmonitor getPointRequest

			由B接口消费

			然后会给出
			spider_binterface_getPointDataRequest
			spider_currentmonitor_getPointResponse

			到达redis就可以实时刷新到页面


		现在流程
			可以分两块
				1、先通过分布器再到kafka												2、原逻辑，直接到kafka，不做分布

				分布器会做优先级处理

				spider_binterface_getPointDataRequest_distribution
				给完之后先过滤
				后面才会到B接口消费



	select * from t_scheduled_task;
		1、task_handler_class  --- 用这个定时类
		2、定时任务：性能数据采集_测试环境21
		3、{"collectTag":"poweroutage","collectTimeout":5000,"deviceLimit":100,"postDelay":1000}     
			取这里面的collecttag：
				1、his_data_collect_device				（设备分组，即每个任务需要去采集的设备有哪些）
				2、his_data_collect_device_metecodes		（测点分组，即每个任务下每个设备需要采集的测点有哪些）
			或用17的
				然后{"collectTag":"test","collectTimeout":5000,"deviceLimit":100,"postDelay":1000}，里面传的collectTag，就是表里某一组的tag，然后就会去批次跑



	定时采集，接口触发/5分钟定时触发一次
	curl --location --request GET '127.0.0.1:8805/v1/dataCollection/startCollectHisDataTaskByTaskId?taskId=17' \
	--header 'Content-Type: application/json' \
	--data-raw '{}'











	current
		binter-server(-- 接收web service)     --发送webservice请求（发送到fsu）、接收webservice响应（再接收fsu）、
										fsu?
											distr
												server-server
												fsu?
													data















 select t1.device_id AS deviceId, t1.device_code AS deviceCode, t1.device_type AS deviceType, t1.device_name AS deviceName, t1.precinct_id AS roomId, t1.manufacturer_id AS manufacturerId, t1.device_model AS deviceModel, t2.fsu_device_id AS fsuDeviceId, t3.device_code AS fsuDeviceCode from t_cfg_device t1 left join t_cfg_monitordevice t2 on t1.device_id=t2.device_id left join t_cfg_device t3 on t3.device_id = t2.fsu_device_id where t1.device_id=?


==> Parameters: 00441006000000200061(String)
<==    Columns: deviceId, deviceCode, deviceType, deviceName, roomId, manufacturerId, deviceModel, fsuDeviceId, fsuDeviceCode
<==        Row: 00441006000000200061, 100100000000068, 68, 锂电池, 01-01-08-04-16-01-03, 1617, 00001008000000018864, 00441006000000200043, 2025120203
<==      Total: 1
```





# 03目前排查

```
排查手段
	apifox一次一次掉
		然后看topic和日志走向
		再用压测再看一遍
```



```
实时请求TOPIC: spider_binterface_getPointDataRequest （currentmonitor)				--存在挤压
分发器监听topic: spider_binterface_getPointDataRequest_distribution （新增，分发器）    --存在挤压
采集结果响应topic: spider_binterface_handlePointDataResponse (不变）					 --存在挤压


不是会被消费掉的吗
```



```
接入个正常的设备
	仅0通道
		然后设备测点类型都要对应上，不能出现测点对应不上
```

