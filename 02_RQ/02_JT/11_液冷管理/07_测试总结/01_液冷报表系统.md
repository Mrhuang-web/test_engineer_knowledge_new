# 01总结

```
需求概述
	涉及服务
		composite, configmanagement, currentmonitor, knowledgemanage, mpp 
		configmanagement  --> 配置查询都走这个服务（113上面）
		knowledgemanage，mpp



涉及库表
	38-中间库
	177-spider库
	114-dh库
	
	执行的sql：
		




测试方法
	一次侧机组（关联设备与测点要对应，否则报表数据出不来）
	一次侧机组要不要取机组名？，不然怎么区分
	运行机状态数据没采集出来
	
	

	平均计算：
		同个机房下（同个设备，同个测点，多个通道）
		同个机房下（不同设备，同个测点，不同通道）
		不同机房下（同个设备，同个测点，不同通道）
		跨楼栋？？

	脚本同步时
		时不时会有别的输入插入，导致插入中间库时失败
	
	1、curl -X GET --header 'Accept: text/plain' 'http://localhost:28090/v1/cinterfaceReader/refreshReaderQueue'
	
	数据流向：
	1、当天会获取昨天和前天（04:00:00,12:00:00,20:00:00）,每个时刻前后1小时距离最近的测点值
	2、单设备测点多通道（会对同个测点多通道，各自取到的最近值，进行平均）
	3、多设备测点多通道（会对同设备同个测点多通道，各自取到的最近值，进行平均;再对不同设备之间进行平均）
	
	4、纵横 - 传入日期，则计算传入日期的前天和昨天的数据
	5、curl - 则是传入前天和昨天的日期，进行获取报表数据(precinct_id，目前传入01？，其他的好像不生效，然后日期好想要拉长点)

测试数据准备






大概描述数据走向
	正向
		1、中间库（数据写入到中间库，site，room，device，signal，d_signalh）
		2、d_signalh -- 会通过C接口（write写入）,再通过另一个服务到kafka,在流向到mpp的dh库中的fact_dwd_signal_value表（这里有device_spatial_id）
		3、通过mpp中dim_liquid_cooling_mete_hour表,过滤写入fact_dwd_signal_value的数据（即需求逻辑）
		4、再通过dwd_device_detail_v,过滤出对应设备和楼栋/机房的映射关系,最后生成dws_liquid_cooling_mete_detail_day
		5、通过curl执行,会根据配置表的信息，对应的precinct中的dim_spatial_id 取找到mpp中的日表数据;还有device中的dim_device_id对应的数据
	
	逆向：
		1、如果没有数据，先排查中间库数据是否有插入（即站点或机楼在中间库所对应的位置，然后在中间库d_signalh表中找）
		2、如果没有数据,那么久需要先通过所选择的机房（或是造数的机房或设备的dim_spatial_id等,取到fact_dwd_signal_value表看是否有同步进行）
		3、同步进行后,有没有转化到dws_liquid_cooling_mete_detail_day表中
		4、如果也有数据,那就需要看动环中分析表是否有问题
	考虑：
		这些环节中都需要考虑到设备id,测点id,测点code,测点no（才能精准判断是哪个）
	
	
	
	疑问（动环跟mpp，之间为啥要用这里有dim_spatial_id这些？）
	


补充问题：
	一次侧机组（关联设备与测点要对应，否则报表数据出不来）
	一次侧机组要不要取机组名？，不然怎么区分
	运行机状态数据没采集出来
	
	目前只有不同设备。且有多个通道号时（计算逻辑：取最近一个点，然后就设备的平均了）
	
	
集团C接口
	下面的操作好像又不行了
	
	液冷数据 - d_signalh 然后同步到mpp的fact  
	（会经过reader服务，里面的lscid要和precinct对应站点和机房的lscid一致，然后resource_code里面的前几位也要一致）
	这样才能同步过去
	write是写入的 （对应哪个什么v啥的）  -- 好像是write不稳定，需要加内存










# curl
curl -X GET "http://localhost:28016/v1/liquidCoolingReport/scheduleLiquidCoolingReport?precinctId=01-08-08-01-11-01&startTime=2025-11-03&endTime=2025-11-07" -H "accept: application/json"
curl -X GET "http://localhost:28016/v1/liquidCoolingReport/scheduleLiquidCoolingReport?precinctId=01-08-08-01-10-01&startTime=2025-10-01&endTime=2025-10-03" -H "accept: application/json"
curl -X GET "http://localhost:28016/v1/liquidCoolingReport/scheduleLiquidCoolingReport?precinctId=01&startTime=2025-10-01&endTime=2025-10-03" -H "accept: application/json"
只能传入楼栋或站点进行统计




c服务，写道kafka，在写入mpp数据库 
precint 找dim_xxx  找到mpp里面机房信息  -- 在找到devcie_spatixxx
C接口每次重启需要调用reader


修改点：
	1、冷设备名称：机房+液冷
	2、条件不用过滤
	3、测点拖进后机房+测点名称
	4、展开不用到设备层级


没配置测点不会展示







fact_dwd_signal_value
  │— 时段 + 码值过滤
  ▼
tmp_dws_liquid_cooling_mete_1
  │— join dim_liquid_cooling_mete_hour（拿到整点）
  │— row_number 取最近整点
  ▼
tmp_dws_liquid_cooling_mete_2
  │— join dwd_device_detail_v（补维度）
  │— 过滤 site_type in (1,2) 且未删除
  ▼
dws_liquid_cooling_mete_detail_day   （日粒度 + 3 时段 + 最近整点快照）



先要执行mpp的采集,mpp的任务执行完之后  再执行curl



fact_dwd_signal_value 找个表近数据有任务
show all routine LOAD
任务关闭了	
MPP数据库  ：show all routine LOAD


状态多个测点，只取最近的






curl -X GET "http://10.12.7.160:32533/v1/liquidCoolingReport/scheduleLiquidCoolingReport?precinctId=01-08-08-01-11-01&startTime=2025-12-10&endTime=2025-12-10" -H "accept: application/json"
```

